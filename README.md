# FBSNNs-in-TF2
在用tf2重写项目之前，我先基于tf1跑通项目，理解内在逻辑。tf2是兼容tf1的，只需要
import tensorflow._api.v2.compat.v1 as tf
tf.disable_v2_behavior()

## 依赖环境
tensorflow 2.9.0
Python	3.10.x	
CUDA	11.2	
cuDNN	8.1.0	
numpy	1.26.4	
这一点原文没有说明，我尝试了好久才配好环境。值得一提的是，在虚拟环境中装好CUDA和cuDNN之后需要在系统变量中的path设置虚拟环境的地址，不然还是会调用全局的cuda，导致版本不匹配。

## 项目逻辑
FBSNNS.py中预留了phi_tf，g_tf，mu_tf，sigma_tf四类抽象方法。在具体的任务中带入即可。原文中使用了HJB方程和BS公式来作为具体的任务。不失一般性，为了节约时间。我只使用了BS公式。
原文在训练后直接输出可视化结果，这样是有问题的，因为没有保存模型参数。我将train和test模块分开了，参数文件保存在model文件夹中（载入后可以继续用这个模型）。

## 训练复现

cpu训练大概是1.几秒一轮，而GPU是0.几秒，似乎没快多少。。。考虑时间因素，原文使用学习率衰减的策略训练了10万轮。我只训练了2万轮，中间调整了一次学习率，毕竟边际收益递减，后面的训练对loss的下降的贡献不大。
figures文件夹中的BSB_524_50.pdf和BSB_524_errors.pdf是我复现的结果。BSB_Apr18_50.pdf和BSB_Apr18_50_errors.pdf是原文的结果。可以看到差别不大，甚至我的训练次数少的模型误差还小一点。（平均值加上两个标准差的红色的线可以理解为置信区间）





